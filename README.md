# ğŸ§  DetecciÃ³n de Emociones en Tiempo Real con DeepFace

[![Python](https://img.shields.io/badge/Built%20with-Python%203.8%2B-blue?style=for-the-badge&logo=python)](https://www.python.org/)
[![OpenCV](https://img.shields.io/badge/Computer%20Vision-OpenCV-green?style=for-the-badge&logo=opencv)](https://opencv.org/)
[![DeepFace](https://img.shields.io/badge/ML%20Library-DeepFace-red?style=for-the-badge&logo=tensorflow)](https://github.com/serengil/deepface)
[![Status](https://img.shields.io/badge/Status-Funcional-brightgreen?style=for-the-badge)]()
[![License](https://img.shields.io/badge/License-GPL%203.0-brightgreen?style=for-the-badge)](https://www.gnu.org/licenses/gpl-3.0.html)

---

## ğŸ¯ DescripciÃ³n General

Este proyecto implementa una **aplicaciÃ³n de escritorio en Python** que utiliza la cÃ¡mara web para detectar y analizar las emociones de un ser humano en tiempo real. Se apoya en la potente librerÃ­a **DeepFace** para el reconocimiento de emociones y **OpenCV** para la captura y visualizaciÃ³n de video. La interfaz visual, con colores adaptados a cada emociÃ³n detectada, muestra la emociÃ³n predominante en espaÃ±ol y ofrece **frases motivacionales o reflexivas** personalizadas segÃºn el estado anÃ­mico, diseÃ±adas para fomentar el bienestar.

La aplicaciÃ³n estÃ¡ optimizada para el rendimiento al procesar solo un subconjunto de frames, lo que permite una experiencia fluida. Es una herramienta interesante para explorar la inteligencia artificial aplicada a la percepciÃ³n humana y cÃ³mo la tecnologÃ­a puede interactuar de forma sensible con nuestras emociones.

---

## âœ¨ CaracterÃ­sticas Destacadas

* **DetecciÃ³n de Emociones en Tiempo Real**: Utiliza DeepFace para identificar la emociÃ³n predominante (feliz, triste, enojado, sorprendido, neutral, miedo, disgusto) a partir del rostro del usuario.
* **Interfaz Visual Adaptativa**: El color de fondo de la ventana cambia dinÃ¡micamente para reflejar la emociÃ³n detectada, creando una experiencia visual inmersiva.
* **Mensajes Personalizados por EmociÃ³n**: Muestra frases relevantes y motivacionales en espaÃ±ol que se actualizan periÃ³dicamente, ofreciendo un soporte o reflexiÃ³n acorde a la emociÃ³n actual.
* **OptimizaciÃ³n de Rendimiento**: Procesamiento de frames cada cierto intervalo (`FRAME_SKIP`) para reducir la carga de la CPU y GPU, garantizando una detecciÃ³n fluida.
* **GestiÃ³n Inteligente de Frases**: Un gestor de frases (`FraseManager`) asegura que las frases no se repitan consecutivamente para la misma emociÃ³n hasta que se hayan mostrado todas las opciones disponibles.
* **Soporte Multilenguaje (EspaÃ±ol)**: Las emociones detectadas y las frases se muestran en espaÃ±ol con tildes y caracteres especiales correctos.
* **FÃ¡cil de Usar**: Interfaz simple para iniciar la detecciÃ³n con solo ejecutar el script.

---

## âš™ï¸ TecnologÃ­as Utilizadas

* **Lenguaje de ProgramaciÃ³n**: Python 3.8+
* **VisiÃ³n por Computadora**: OpenCV (`cv2`)
* **AnÃ¡lisis Facial y Emocional**: DeepFace
* **ManipulaciÃ³n de ImÃ¡genes**: `numpy`
* **Interfaz GrÃ¡fica de Usuario (GUI)**: Implementada directamente con OpenCV para la visualizaciÃ³n.
* **Manejo de Texto y Fuentes**: PIL (Pillow: `Image`, `ImageDraw`, `ImageFont`)
* **Otras LibrerÃ­as**: `random`, `time`, `collections` (deque), `os`, `sys`, `locale`.

---

## ğŸ“‚ Estructura del Repositorio

El proyecto se compone de un Ãºnico archivo principal que contiene toda la lÃ³gica.

```
Deteccion_Emociones/
â”‚
â”œâ”€â”€ main.py                     # Script principal de la aplicaciÃ³n
â”œâ”€â”€ Arial.ttf                   # Fuente (opcional, si se desea una fuente especÃ­fica)
â”œâ”€â”€ .gitignore                  # Archivos y carpetas excluidas del control de versiones
â””â”€â”€ README.md                   # DocumentaciÃ³n del proyecto
```

**Nota**: Para la visualizaciÃ³n del texto con caracteres especiales y un formato especÃ­fico, se ha incluido la capacidad de cargar una fuente `Arial.ttf` en el mismo directorio del script. Si esta fuente no estÃ¡ presente, el sistema usarÃ¡ una fuente por defecto.

---

## ğŸš€ Instrucciones de EjecuciÃ³n

### Requisitos

* **Python 3.8+**
* **pip** (gestor de paquetes de Python)
* **Una cÃ¡mara web funcional**

### Pasos para la ejecuciÃ³n

1.  **Clonar el repositorio**:
    ```bash
    git clone https://github.com/SebastianVega4/Captura_Emociones_Cam_web
    cd Deteccion_Emociones
    ```

2.  **Crear un entorno virtual (opcional pero recomendado)**:
    ```bash
    python -m venv venv
    source venv/bin/activate  # En Linux/macOS
    # venv\Scripts\activate   # En Windows
    ```

3.  **Instalar dependencias**:
    ```bash
    pip install opencv-python numpy deepface pillow
    ```
    (DeepFace descargarÃ¡ automÃ¡ticamente sus modelos pre-entrenados la primera vez que se ejecute.)

4.  **Ejecutar la aplicaciÃ³n**:
    ```bash
    python main.py
    ```

5.  **InteracciÃ³n**:
    * AsegÃºrate de que tu rostro sea visible para la cÃ¡mara.
    * La ventana mostrarÃ¡ tu imagen con el fondo y texto adaptados a tu emociÃ³n detectada.
    * Presiona la tecla `'q'` para salir de la aplicaciÃ³n.

---

## ğŸ‘¨â€ğŸ“ Autor

Desarrollado por **SebastiÃ¡n Vega**

ğŸ“§ *Sebastian.vegar2015@gmail.com*

ğŸ”— [LinkedIn - Johan SebastiÃ¡n Vega Ruiz](https://www.linkedin.com/in/johan-sebastian-vega-ruiz-b1292011b/)

---

## ğŸ“œ Licencia

Este repositorio se encuentra bajo la Licencia **GPL 3.0**.

**Permisos:**
* Uso comercial
* ModificaciÃ³n
* DistribuciÃ³n
* Uso privado

---

Facultad de IngenierÃ­a â€” IngenierÃ­a de Sistemas ğŸ§©

**ğŸ« Universidad PedagÃ³gica y TecnolÃ³gica de Colombia**
ğŸ“ Sogamoso, BoyacÃ¡ ğŸ“

Â© 2025 â€” Sebastian Vega
